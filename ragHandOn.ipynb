{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Extract Text From PDF file"
      ],
      "metadata": {
        "id": "ZpmpdT4lTKfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjjuyeegTu7W",
        "outputId": "da40aad5-021f-4553-8eee-e1899f97f585"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Vuc4Wz_PPofg"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in doc:\n",
        "        page_text = page.get_text()\n",
        "        if page_text:  # Only add non-empty text\n",
        "            text += page_text + \"\\n\"\n",
        "\n",
        "    doc.close()\n",
        "    if text.strip():\n",
        "        return text\n",
        "    else:\n",
        "        print(\"Warning: No extractable text found in the PDF (might be scanned or empty).\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file_path = '/content/2306.12345v2.pdf.crdownload'\n",
        "extracted_text = extract_text_from_pdf(pdf_file_path)"
      ],
      "metadata": {
        "id": "zC7M4cclTR0U"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Split the Text into Chunks"
      ],
      "metadata": {
        "id": "c7icgMfxUpBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuY1mPgfVu_H",
        "outputId": "37488134-edc2-4ab2-90a3-e47ff540821c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def split_text(text, max_tokens=300):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(chunk.split()) + len(sentence.split()) <= max_tokens:\n",
        "            chunk += sentence + \" \"\n",
        "        else:\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sentence + \" \"\n",
        "    if chunk:\n",
        "        chunks.append(chunk.strip())\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "ZSlHW8VhUokX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = split_text(extracted_text)\n",
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbW4ltJ9VONL",
        "outputId": "b9040add-f7de-407e-99ca-b6a4f4d3294a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Effect of Noise on the Emergence of Continuous Norms and its Evolutionary\\nDynamics\\nStavros Anagnou, Daniel Polani and Christoph Salge\\nAdaptive Systems Research Group, School of Computer Science, University of Hertfordshire\\ns.anagnou@herts.ac.uk\\nAbstract\\nWe examine the effect of noise on societies of agents\\nusing an agent-based model of evolutionary norm emergence. Generally, we see that noisy societies are more selfish,\\nsmaller and discontent, and are caught in rounds of perpetual\\npunishment preventing them from flourishing. Surprisingly,\\ndespite the detrimental effect of noise on the population,\\nit does not seem to evolve away. We carry out further\\nanalysis and provide reasons for why this might be the\\ncase. Furthermore, we claim that our framework that evolves\\nthe noise/ambiguity of norms is a new way to model the\\ntight/loose framework of norms, suggesting that despite\\nambiguous norms’ detrimental effect on society, evolution\\ndoes not favour clarity. Introduction 1\\nThe social world is replete with norms, an important aspect\\nof organising societies. Social norms reduce the degrees\\nof freedom in the actions of individuals, making them\\nmore predictable and stabilising societies (FeldmanHall and\\nShenhav, 2019). Norms also enable unrelated agents to\\nmanage shared resources (Mathew et al., 2013) , thereby\\nextending cooperation beyond genetic relatives (Richerson\\net al., 2016). Norm\\nemergence\\nis\\nusually\\nstudied\\nwith\\ndiscrete\\nbehaviours. Game theory tends to consider moral behaviour\\nto be composed of discrete actions: cooperate and defect\\n(Axelrod, 1986), hawk and dove (Smith, 1982), stag\\nand hare (Skyrms, 2003). Other examples of discrete\\nnorms include political party affiliation, coordinating or\\nnot coordinating (Lewis, 1969; McElreath et al., 2003) or\\nadopting a given behaviour e.g. a possession norm (Epstein\\nand Axtell, 1996; Flentge et al., 2001).',\n",
              " 'We know, however,\\nthat norms are not always this discrete, and a large number\\nof norms exist on a continuous spectrum of behaviour, e.g. what amount is acceptable to take from a shared resource,\\nhow fast you walk, how close you stand next to someone\\n1This paper has been updated to address an error in\\nthe implementation of the mutation operator, discovered after\\npublication. We have added asterisks in the main document where\\nthe reader should refer to the errata document. during a conversation (Kelly and Setman, 2021). These have\\nreceived much less attention in terms of modelling (Le and\\nBoyd, 2007), with the exception of continuous opinions as\\nmodelled in the closely related field of opinion dynamics\\n(Flache et al., 2017). Previous work using continuous behaviour includes\\ncontinuous iterated prisoners dilemma (Le and Boyd, 2007)\\n(on a scale of 0 complete defection, to 1, cooperation). In general, cooperation in continuous dilemmas is less\\nstable and it is harder for cooperation to invade a\\npopulation of defectors (Le and Boyd, 2007). Bendor\\net al. (1991), investigated how noise affected the success of\\nfixed strategies in a continuous prisoners dilemma. They\\nshowed that populations of generous strategies were more\\nsuccessful because generous strategies avoided spiraling\\ninto rounds of mutual recrimination in noisy environments. Going beyond continuous game theory, Aubert-Kato et al. (2015) investigated the emergence of frugal and greedy\\nbehaviours in an embodied version of a dilemma where\\nagents varied in how long they exploited a food source\\n– the longer it exploits the food source, the more selfish\\nthe agent is. Michaeli and Spiro (2015) showed how\\n“liberal” and “conservative” punishment regimes can affect\\nthe polarisation of a continuous opinion. Further, previous\\nwork on iterated prisoners dilemma by Ashlock et al. (2006)\\nshowed that even small differences in implementation, e.g.',\n",
              " 'representation choice, can lead to significantly different\\ndynamics. We intend to combine these previous elements together\\nto investigate the effects of noise on the emergence\\nof continuous social norms. We investigate this in\\nan evolutionary agent-based simulation, comparing agent\\nsocieties with deterministic and probabilistic behaviours\\nto see if noise significantly changes the dynamics of the\\nsociety, i.e. norm emergence and other properties of agent\\nsocieties. To achieve this, we evolve three continuous\\nnorms. Uniquely, we also evolve the level of noise on each\\nof these properties. This allows us to investigate the effect of\\nnoise on a continuous model of norm emergence, which is of\\nuse to modelers considering whether or not to include noise\\narXiv:2306.12345v2  [cs.MA]  30 Dec 2023\\n\\nin their models. Further, by making the amount of noise a\\nvariable that is available to evolution, it allows us to study\\nthe evolutionary dynamics of noise. We define criteria for norm emergence in a continuous\\nsystem and show that our deterministic societies obey these\\ncriteria. We find that deterministic societies tend to be\\nless selfish, less hypocritical and less discontented, with\\nagents sharing resources more effectively and sanctioning\\neach other less. In contrast, noisy societies tend to fall into\\nperpetual punishment of each other despite the abundance of\\nresources. This begs the question, if noise is detrimental to the\\nagent society, why does it not evolve away? We show\\nthat there does not seem to be an evolutionary pressure\\nto eliminate noise and offer some reasons as to why this\\nmay be the case. Further, we suggest our model offers\\nsome insight into thinking about the evolution of loose and\\ntight societies. The tightness-looseness framework looks\\nat culture in terms of the strength of their cultural norms\\n(number and clarity) and strength of punishment when a\\nnorm is violated.',\n",
              " 'Tight cultures have stronger norms and\\npunishments and loose cultures have more vague norms\\nwith less harsh punishments. This framework provides\\ninsights into the function of norms, with cultures tightening\\nin response to threats, making them better at dealing with\\nthem. Our model expands the existing work by considering\\nthe noise inherent in looser societies that have more vague\\nor ambiguous social norms (Gelfand et al., 2006; Roos et al.,\\n2015; Pan et al., 2021). Model and Experiments\\nThe following section introduces a multi-agent model\\nwe developed to study the effect additive noise has on\\ncontinuous norm emergence. We study two experimental\\nconditions in the model. In the deterministic case,\\nthe behavior of each agent is defined by three internal,\\ncontinuous variables (Bite Size (B), Sanction Threshold (T)\\nand Sanction Strength (S)). In the probabilistic case, we add\\nGaussian noise to those variables each time they are used to\\ndetermine behavior. The strength (variance) of this added\\nnoise is defined for each of the three internal values by\\nanother three agent-specific values, respectively - i.e. BN,\\nTN and SN. The simulation can be separated into different\\nsteps, as visualized in Fig. 1, which are defined as follows:\\nInitialisation\\nAt the beginning of the simulation, we create 100 agents and\\nset the resource level to 1000 units. Each agent’s internal\\nvalues for B, S and T are initialized to uniformly random\\nvalues between 0.0 and 1.0. For the probabilistic model,\\neach agent’s noise values (BN, TN and SN) are initialized\\nbetween 0.0 and 0.5. Each agent’s energy level is set to 10. After initialization, the simulation proceeds in rounds. Each\\nFigure 1: Flow diagram describing the stages of the agent-\\nbased simulation.',\n",
              " 'round has a different, randomized order of all agents, and\\neach of the following steps is performed in that order. Eat\\nWhen it is their turn, each agent tries to consume resources\\naccording to their Bite Size (B). This value is added to\\ntheir internal energy and removed from the global resource\\nlevel. If there are no resources left, the agent gets no energy. The higher the value, the more greedy/selfish the agent is\\ncompared to other agents. If all agents eat at a higher\\nBite Size, the environment will not be able to support as\\nmany agents; thereby exhibiting ’tragedy of the commons’\\ndynamics (Hardin, 1968). Sanction\\nDuring their turn, each agent can observe the actually\\nconsumed resources of the 10 previous agents. Each agent\\nchecks if the previous agents ate more than its own internal\\nSanctions Threshold (T); if so, it sanctions them. In other\\nwords, T is the amount of deviance an agent tolerates\\nbefore punishing another agent, i.e. what an agent finds\\nacceptable. Sanctioning means the agent reduces the other\\nagent’s internal energy by its own Sanction Strength (S), and\\n\\nFigure 2: The average value of each trait in the population plotted over time. Deterministic (left) and probabilistic (right). Individual runs are plotted as coloured lines and the average of those runs is plotted as a black line. N = 34 per condition. it also pays a sanctioning cost of 0.1 ∗S, which is subtracted\\nfrom its own energy level. Metabolise\\nEach agent has their energy level reduced by 0.01 during\\neach round. Death and Reproduction\\nAfter those steps, the simulation checks if any agents have\\nan energy level lower than 0.0, in which case they are\\nremoved from the simulation. Then any agent with an\\nenergy level larger than 10 gets to reproduce.',\n",
              " 'Reproduction\\nmeans we generate a copy of the agent, with the same 3\\nor 6 internal values, mutated with a 0.1 chance. [Updated]\\nWe planned to add Gaussian noise with 0 mean and 0.1\\nvariance to each of those values, but due to an error in the\\nimplementation, the value is just set to 1.0 if a mutation is\\ntriggered. The results in this paper, are for this, extreme\\nmutation operator. The erratum attached to the end shows\\ncomparable plots for the Gaussian mutation operator, and\\nprovides data to show that nearly all results discussed here\\nare true for both mutation operators [End Update] The\\nenergy of the child and parent are both set at half the parent’s\\nprior energy level. Before the next round starts, we add 100\\nunits of resources to the resource level. Creating Probabilistic Behaviour\\nTo create the probabalistic behaviour, we used a Gaussian\\nfunction each time the agent consumed from the shared\\nresource or punished another agent. Using their value\\nand accompanying standard deviation (noise parameter) to\\ncreate a value for the amount of food eaten B, how tolerant\\nthey are T and how harshly they punish S, e.g. for each\\ninstance of sanctions we select the strength from a normal\\ndistribution with a mean of S and a standard deviation of\\nSN. This added noise can be interpreted either as behavioral\\nor perceptual error. Implementation Choices\\nThe evolutionary dynamics in this simulation are created by\\ndifferential reproduction, rather than by defining an explicit\\nfitness function and selection process. Since the order agents\\neat and sanction each other is sequential, it means agents\\nat the front of the queue have an advantage, as they get to\\nconsume from the resource first.',\n",
              " 'Conversely, being last in\\nthe queue also has an advantage as there is no one behind\\nthe agent to sanction them. To minimise the impact of\\nthese asymmetries on the results, we randomise this order in\\neach round. We limit the initial values for the noise values\\nto [0.0, 0.5], because some initial simulation with the full\\nrange resulted in very volatile dynamics that were hard to\\nanalyze. But after initialization, it is possible for the noise\\nparameters to have any value between 0.0 and 1.0 so they\\ncan adapt in that direction. We explored further parameter\\nsettings not reported here (varied agent metabolism, cost of\\nsanctions), which produced results similar to those in this\\npaper. Note that the deterministic condition can be seen as\\na special case of the probabilistic condition, where the three\\n\\nFigure 3: The population-level variance (the variance of a trait in each population) of each trait plotted over time. Deterministic\\n(left) and probabilistic (right). Individual runs are plotted as coloured lines and the average of those runs is plotted as a black\\nline. N = 34 per condition. noise parameters are very close to 0 for all agents. Results\\nContinuous Norm Emergence\\nFirst we want to answer the questions, is this a model for\\nthe emergence of continuous norms? Usually in discrete\\nmodels there is an arbitrary threshold, such as 80 percent\\nof the population must possess that behaviour for it to be\\nconsidered a norm (Savarimuthu and Cranefield (2011)). Since our behaviours are continuous, and its not clear what\\nit would mean for two agents to have the same behaviour,\\nwe define criteria on how to assess norm emergence in a\\ncontinuous context. 1.',\n",
              " 'The behaviour converges and stabilises:\\nDo traits\\ndecrease terms in variance across the population from\\nwhere they began,\\nand do the average behaviours\\nstabilise? This would be indicated by a decreasing value\\nfor the variance of a given behaviour across the agent\\npopulation, and a lack of change of the average behaviour\\nover time. 2. The behaviour the population stabilises at is arbitrary\\nacross runs to a certain extent: This criterion ensures\\nthe resultant behaviour is not fully due to environmental\\nscaffolding, meaning when the behaviour is the only\\nrational/viable action given the environmental constraints,\\ne.g. a population level preference for walking over a\\nbridge as opposed to walking across lava would not be\\nconsidered a norm (Westra and Andrews, 2022). This\\nwould be indicated by repeated simulations stabilizing at\\ndifferent average values. Note that this requires some\\nlevel of randomness in the simulation, with different\\nseeds. Further to our stipulations, we clarify that we are talking\\nabout norms under the general definition of normative\\nregularities: \"A socially maintained pattern of behavioral\\nconformity within a community. \"(Westra and Andrews,\\n2022). We take this definition rather than a rule-based one,\\nwhich requires higher cognitive capacities such as language\\n(required to express the rule) (Kelly and Setman, 2021). Further, we think it is a wider framework that encompasses\\na broader range of phenomena that are of interest. This\\npermissive of \"bottom-up\" approach may help us reveal\\nthe building blocks of normative cognition (Westra and\\nAndrews, 2022; de Waal and Ferrari, 2010). In Fig. 2,\\nwe see that in our deterministic simulation, after about 200\\ntics, all agent traits manage to settle on a particular value. This value is arbitrary to a certain extent with different\\nruns settling at different values.',\n",
              " 'This is important as it\\nmeans that the behaviour is indeed a norm and not just a\\nproduct of environmental scaffolding, i.e. the only rational\\naction given the environmental circumstances (Westra and\\nAndrews, 2022). In the probabilistic cases, it seems that\\nnorms are a lot more volatile, with average values in flux. Figure 4: Various agent and population properties plotted over time. Deterministic (left) and probabilistic (right). Individual\\nruns are plotted as coloured lines and the average of those runs is plotted as a black line. N = 100 per condition. Further, if we look at the population level variances of\\neach trait in Fig. 3 we see that Bite Size converges onto\\na much lower level than it began, thereby satisfying our\\ncriteria for norm emergence as the population converges\\non a shared behaviour. On the other hand, the population\\nlevel variance of Sanction Threshold and Sanction Strength\\ndoes not always decrease, so it is harder to make a case\\nfor the population to converge on a norm for the latter two\\ntraits. This effect doesn’t happen as much in the noisy case\\n(Fig. 3), although there is some convergence for Sanction\\nThreshold and Sanction Strength. However, this could be\\nexplained by the fact that probabilistic populations tend to\\nhave much lower populations than deterministic ones (Fig. 4), which could be decreasing the variance through random\\ndrift. Comparison Deterministic vs. Probabilistic Model\\nProbabilistic agent societies are generally more selfish\\nand have less stable cooperation*. Fig. 4 shows that\\ndeterministic societies tend to have lower Bite Sizes than\\nprobabilistic ones, meaning the societies tend to be less\\nselfish as they are all consuming less.',\n",
              " 'Further, the norm\\nseems to be more stable in the deterministic condition,\\nwith many cases in the probabilistic condition that initially\\nsettled on low Bite Sizes breaking out into higher Bite\\nSizes. Particularly striking is that in 100 runs none of\\nthe deterministic runs broke away, suggesting very stable\\nnorms in the deterministic population and volatile in the\\nnoisy populations. Further, when this experiment was\\ndone with an initial noise range of [0.0, 1.0] as opposed\\n\\nto [0.0, 0.5], the average value of Bite Size went up to\\n0.9, indicating very high levels of selfishness. Values\\nfor the other two norm traits (Sanction Threshold and\\nSanction Strength) are comparable between probabilistic\\nand deterministic societies, but as with Bite Size, the runs\\nin the probabilistic version are more volatile (Fig. 2). The probabilistic populations are dramatically smaller (Fig. 4), with populations of 20 compared to thousands in the\\ndeterministic case. Only a handful of the probabilistic\\npopulations manage to reach comparable population levels\\nto the deterministic populations. Probabilistic societies\\nare more hypocritical (Fig. 4). We defined hypocrisy\\nas an agents sanction threshold being lower than its own\\nBite Size (Tself > Bself). After an initial increase at\\nthe beginning of the simulation, both deterministic and\\nprobabilistic populations see a sharp decrease. However,\\nrates of hypocrisy are much lower in the deterministic\\ncase (around 0) compared to hypocrites in the probabilistic\\ncase (around 0.05), and the noisy runs are generally more\\nvolatile, with numerous runs breaking out into high numbers\\nof hypocrites. Initially, probabilistic and deterministic societies also\\nhave similar levels of norm convergence as measured by\\ntrait variance decreasing initially and staying at around\\n0.1. However, as in Fig. 2, this level of convergence\\nis less stable in the probabilistic condition*.',\n",
              " 'Further,\\nsince the populations are much smaller in the probabilistic\\ncondition, this may bias the population level variance\\nmetric, so we should not read too much into this result. Further, the small populations mean genetic/cultural drift\\neffects could overpower subtle selection pressures. Despite\\nthe small populations, however, there is still a significant\\namount of births/deaths (data not shown here), suggesting\\nselection is still happening. To address the effects of small\\npopulations in the future, we will have a fixed population\\nwith replacement instead of a dynamic one. But for now,\\nsince we are interested in seeing the effect on noise on the\\nsize of the populations as well, we will keep it as is. Strangely,\\nthe\\nreason\\nfor\\nlow\\npopulations\\nin\\nthe\\nprobabilistic population is not a lack of resources. To see\\nthe real reason, we look at the amount of energy lost due to\\npunishment of the agents (Fig. 4). This plot shows that the\\namount of energy was lost either as a result of damage from\\nsanctions or cost of executing sanctions. In the deterministic\\ncase, we see a spike in sanctions at the onset if the simulation\\nas agents punish each other due to the diversity of norms. The society then converges toward a norm as the sanctioning\\ndecreases. In the probabilistic case, it seems the societies\\ndo not adequately manage to converge most of the time,\\nresulting in this period of adjustment never ending, leading\\nto discontented society marred by perpetual punishment. This may be the reason agents raise their Bite Size in order\\nto better protect themselves against punishment; in a high-\\nnoise society has hypocrites, you will likely be punished\\nanyway, so there is no rational reason to be generous and\\nhave a low bite size.',\n",
              " 'It is important here to mention our\\nsimulation is not a case of limited resources; in fact, the\\nregrowth rate of the simulation is quite high to assess the\\ndynamics of noise in plentiful conditions. In conclusion, probabilistic populations are more selfish,\\nhypocritical,\\ndiscontented\\nand\\nless\\nstable\\nwhile\\nthe\\ndeterministic populations managing to reach drastically\\nhigher populations with the same amount of resources. Figure 5: The average standard deviation (noise) for each\\ntrait plotted over time. Individual runs are plotted as\\ncoloured lines and the average of those runs is plotted as\\na black line. N = 100 per condition. Noise Evolution\\nGiven that noise in our model seems to be detrimental to\\na society overall, and noting that the deterministic model\\nis just a special case of the probabilistic model, we would\\nexpect that our models evolve away the noise. But if we look\\nat the development of the average value for the three added\\nnoise parameters, we do not see a decrease of noise (Fig. 5). On the contrary, if we just look at the first 500 steps, the\\naverage noise seems to slowly increase. This could in part\\nbe explained by a random walk, since we initialise between\\n[0.0, 0.5] but allow for noise to evolve to the full range of\\n[0.0, 1.0]. If there was no evolutionary pressure, we would\\nexpect the noise parameters to drift towards 0.5. To investigate the evolutionary dynamics of noise, we\\nlooked at how the standard deviation evolved over time (Fig. 5). We see that average noise apart from small deviations\\ndoes not really seem to increase.',\n",
              " 'With the individual\\nruns looking like random walks and the average not really\\nchanging.To further investigate why this is happening and to\\n\\nmake sure this lack of evolution is not due to the shortness\\nof the runs, we did the following. We first ran a sample of\\n34 runs for each condition for 5000 time steps (10x longer\\nthan previous experiments) and then compared noisy runs\\nthat were successful (i.e. reach large populations larger than\\n5000, which is comparable to the deterministic case) with\\nthose that were not successful (i.e. where the population\\ncollapse or stayed at low population numbers). Interpreting the Evolution of Noise\\nIn the longer runs, we see that noise seems to slightly\\nincrease for Bite Size for all runs Fig. 6 (left panels). But if\\nwe look at only the successful runs (right panels), it seems\\nthat on average they don’t really change in terms of their\\nvalue over time. For some of the runs, this might not be so\\nmuch due to evolutionary adaptation, but the fact that the\\nruns started with low noise to begin with and happened to be\\nbetter at surviving. This being said, a minor proportion of\\nsuccessful runs had an initial increase in noise but eventually\\nsettled at low noise values. It seems then that for Bite Size,\\nsuccessful runs (those that reach higher populations) are\\nruns that, by chance, started at the low noise levels. If we look at the noise for Sanction Threshold (tolerance)\\n(TN), we see a similar pattern: a slight increase in noise\\noverall if we look at all of the runs but the majority of the\\nsuccessful runs start at low noise and remain there.',\n",
              " 'So\\nalthough the graphs show that we could reduce noise by\\nselecting populations by their overall performance, noise\\nlevel does not seem to decrease when selection occurs on\\na per agent basis. In contrast to the other two traits, Sanction Strength noise\\n(SN) seems to increase in both successful and unsuccessful\\nruns*, in spite of the fact that noise is initialised at [0, 0.5]\\n(Fig. 6). Specifically, there seems to be a region between\\n0.6 and 0.8 where the most successful runs seem to settle,\\nwith unsuccessful runs above and below this region. One\\ncould interpret this as being a selection pressure favouring\\nan intermediate level of Sanction Strength noise, however\\nmore experiments with runs starting at a wider range of noise\\nwould be needed to conform this. Taken together, this results seem to suggest that although\\nnoise makes agent populations less successful, there doesn’t\\nseem to be an evolutionary process that reduces noise, in\\nfact, in the case of Sanction Strength, evolution may increase\\nnoise. Discussion\\nWe present a model of continuous norm emergence to show\\nthe effects of noise on the dynamics of norm emergence and\\nthe simulation more generally. We first showed that deterministic societies satisfy our\\ncriteria for norm emergence:\\n• 1: That they converge on behaviours compared to the start\\nof the simulation; and\\n• 2: That the norm is somewhat arbitrary, meaning not\\nthe only rational action given the circumstances i.e. environmental scaffolding (Westra and Andrews, 2022). Second, we showed that deterministic societies compared\\nto noisy ones are: more able to settle on norms, distribute\\nresources effectively (altruism),\\nless hypocritical,\\nless\\ndiscontent and are more stable in these properties over time.',\n",
              " 'In contrast, noisy societies do not prosper because they\\nhave high levels of sanctioning not seen in deterministic\\nsocieties, falling into rounds of perpetual punishment. This\\nresult goes against the \"mad man theory\" hypothesis, where\\nan adversary in a negotiation is more likely to stand\\ndown if they think their opponent (in our simulation, the\\nagent sanctioning) is unpredictable to avoid provoking them\\n(McManus (2019)). In our simulation, it appears that noisy\\npunishment only seems to incentivise agents to increase\\ntheir provoking behavior (breaking norms by increasing Bite\\nSize). This occurs because they will be punished whether\\nthey obey a norm or not, so they might as well consume\\nas much as they can to increase their chances of survival. Although, the detrimental effects of noisy sanctions may be\\ndue to the fact that both the punishment behaviours (S and\\nT) and eating behaviour (B) are noisy, further analysis by\\nadding noise to only one of the behaviours e.g. B or T would\\nbe needed to confirm this. The widespread instability of noisy societies raised\\nthe question: if noise is detrimental, wouldn’t it evolve\\naway? Through further analysis, we showed that although\\npopulations with low levels of noise ended up being more\\nsuccessful (reaching higher populations), there wasn’t an\\nevolutionary trend toward reducing noise, in fact in some\\ncases there seemed to be an evolutionary pressure to increase\\nnoise. We offer some explanations why this may be happening. Firstly, for noise to be selected against there might need\\nbe group selection, as deterministic societies tend to be\\nmuch larger, they would be able to out compete smaller\\nnoisy groups. Secondly, although high levels of noise\\nare detrimental to the group, there might be a benefit to\\nthe individual of having noise; perhaps it enables them to\\navoid punishments.',\n",
              " 'Further, one agent lowering their noise\\nwould not necessarily benefit them enough to dominate the\\npopulation if the rest of society still has high levels of noise. A further contribution of this paper is that it may\\noffer a way to model/think about the evolution of cultural\\ntightness/looseness (Gelfand et al., 2006). Which is defined\\nas 1.\\nstrength of sanctioning (tolerance to deviance\\nfrom norms) and 2.\\nstrength of social norms (number\\nand clarity). Tight cultures have stronger norms and\\npunishments and loose cultures have vaguer norms with\\nless harsh punishments (Gelfand et al., 2006; Roos et al.,\\n2015). We refine 1. by differentiating between tolerance to\\ndeviation (i.e. sanction threshold) and also the strength of\\npunishment when someone deviates (i.e. sanction strength). Figure 6: The average standard deviation (noise) for each trait plotted over time. All runs (left) and only runs with\\npopulations > 1000 (right). Individual runs are plotted as coloured lines and the average of those runs is plotted as a black\\nline. N = 34 per condition. Further, our model could be a new way to model the\\nevolution of clarity of social norms using noise (2). Finally,\\ncomputer models studying tightness and looseness assume\\ndiscrete behaviours, we relax this assumption by grounding\\nour study in a continuous modelling framework (Pan et al.,\\n2021). Taking this lens on our simulation, we could claim\\nthat the clarity of norms (tightness) can’t be evolved despite\\nthere being an ostensible selection pressure against it. This\\nis a peculiar finding, as it would imply although societies\\nwith vague rules are at a disadvantage, ambiguity persists. Future Work\\nIn our future work we would like add the following\\nextensions. Currently the regrowth rate of the shared\\nresource is static.',\n",
              " 'We could vary this and make the resource\\ngrowth dynamic by having \"seasons\" and see the resultant\\ndynamics. Further, we only studied vertical cultural\\ntransmission but didn’t include horizontal transmission,\\nwhere individuals in the same generation copy each other’s\\nstrategies. In contrast to other models of tightness and\\nlooseness, our model has three norms instead of one, we\\ncould add more norms and analyse the interplay between\\nthe \"tightness\" and \"looseness\" of different norms. Finally,\\nto further study the evolutionary dynamics of noise; we\\nshould compare different combinations of traits with and\\nwithout noise, e.g. have a noisy punishment threshold but\\ndeterministic bite size and punishment strength. Acknowledgements\\nWe would like to thank Niki Papadogiannaki, Imran Khan\\nand the anonymous reviewers for their helpful comments\\nand feedback. Stavros Anagnou is supported by a\\nstudentship from the University of Hertfordshire. References\\nAshlock, D., Eun-Youn Kim, and Leahy, N. (2006). Understanding\\nrepresentational sensitivity in the iterated prisoner’s dilemma\\nwith fingerprints. IEEE Transactions on Systems, Man and\\nCybernetics, Part C (Applications and Reviews), 36(4):464–\\n475. Aubert-Kato,\\nN.,\\nWitkowski,\\nO.,\\nand Ikegami,\\nT. (2015). The Hunger Games: Embodied agents evolving foraging\\nstrategies on the frugal-greedy spectrum. In ECAL 2015,\\npages 357–364. The MIT Press. Axelrod, R. (1986). An Evolutionary Approach to Norms. American Political Science Review, 80(4):1095–1111. Bendor, J., Kramer, R. M., and Stout, S. (1991). When in Doubt...:\\nCooperation in a Noisy Prisoner’s Dilemma. Journal of\\nConflict Resolution, 35(4):691–719. de Waal, F. B. and Ferrari, P. F. (2010). Towards a bottom-\\nup perspective on animal and human cognition. Trends in\\nCognitive Sciences, 14(5):201–207. Number: 5. Epstein, J. M. and Axtell, R. (1996). Growing artificial societies:\\nsocial science from the bottom up. Complex adaptive\\nsystems. Brookings Institution Press, Washington, D.C.\\n\\nFeldmanHall, O. and Shenhav, A. (2019). Resolving uncertainty\\nin a social world.',\n",
              " 'Nature Human Behaviour, 3(5):426–435. Number: 5. Flache, A., Mäs, M., Feliciani, T., Chattoe-Brown, E., Deffuant,\\nG., Huet, S., and Lorenz, J. (2017). Models of Social\\nInfluence: Towards the Next Frontiers. Journal of Artificial\\nSocieties and Social Simulation, 20(4):2. Flentge, F., Polani, D., and Uthmann, T. (2001). Modelling the\\nEmergence of Possession Norms using Memes. Journal of\\nArtificial Societies and Social Simulation, vol. 4(no. 4). Gelfand, M. J., Nishii, L. H., and Raver, J. L. (2006). On the nature\\nand importance of cultural tightness-looseness. Journal of\\nApplied Psychology, 91(6):1225–1244. Hardin, G. (1968). The Tragedy of the Commons: The population\\nproblem has no technical solution; it requires a fundamental\\nextension in morality. Science, 162(3859):1243–1248. Kelly, D. and Setman, S. (2021). The Psychology of Normative\\nCognition. In The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University, spring 2021\\nedition. Le,\\nS. and Boyd,\\nR. (2007). Evolutionary dynamics of\\nthe continuous iterated Prisoner’s dilemma. Journal of\\nTheoretical Biology, 245(2):258–267. Lewis, D. K. (1969). Convention:\\na philosophical study. Blackwell, Oxford, nachdr. edition. Mathew, S., Richerson, P. J., and Van Veelen, M. (2013). Human\\nCooperation among Kin and Close Associates May Require\\nEnforcement of Norms by Third Parties. In Cultural\\nEvolution. The MIT Press. McElreath, R., Boyd, R., and Richerson, P. (2003). Shared Norms\\nand the Evolution of Ethnic Markers. Current Anthropology,\\n44(1):122–130. Number: 1. McManus, R. W. (2019). Revisiting the Madman Theory:\\nEvaluating the Impact of Different Forms of Perceived\\nMadness\\nin\\nCoercive\\nBargaining. Security\\nStudies,\\n28(5):976–1009. Michaeli, M. and Spiro, D. (2015). Norm conformity across\\nsocieties. Journal of Public Economics, 132:51–65. Pan, X., Gelfand, M., and Nau, D. (2021). Integrating evolutionary\\ngame theory and cross-cultural psychology to understand\\ncultural dynamics. American Psychologist, 76(6):1054–1066.',\n",
              " 'Richerson, P., Baldini, R., Bell, A. V., Demps, K., Frost, K., Hillis,\\nV., Mathew, S., Newton, E. K., Naar, N., Newson, L., Ross,\\nC., Smaldino, P. E., Waring, T. M., and Zefferman, M. (2016). Cultural group selection plays an essential role in explaining\\nhuman cooperation: A sketch of the evidence. Behavioral\\nand Brain Sciences, 39:e30. Roos, P., Gelfand, M., Nau, D., and Lun, J. (2015). Societal\\nthreat and cultural variation in the strength of social norms:\\nAn evolutionary basis. Organizational Behavior and Human\\nDecision Processes, 129:14–23. Savarimuthu, B. T. R. and Cranefield, S. (2011). Norm creation,\\nspreading and emergence: A survey of simulation models of\\nnorms in multi-agent systems. Multiagent and Grid Systems,\\n7(1):21–54. Skyrms, B. (2003). The Stag Hunt and the Evolution of Social\\nStructure. Cambridge University Press, 1 edition. Smith, J. M. (1982). Evolution and the Theory of Games. Cambridge University Press, 1 edition. Westra, E. and Andrews, K. (2022). A pluralistic framework for\\nthe psychology of norms. Biology & Philosophy, 37(5):40. Erratum\\nThis is an erratum to The Effect of Noise on the Emergence of\\nContinuous Norms and its Evolutionary Dynamics, published\\nin the Proceedings of the 2023 Conference on Artificial Life. After\\npublication, we discovered an error in the mutation operator. In\\nthis correction, we will describe the error, outline what dynamics\\nwould produce the results we initially presented, and then compare\\nthem with simulation results with the mutation operator working\\nas described in the original paper. We go through the claims of the\\noriginal paper, discussing any possible differences in the outcomes. Overall, the main results of the paper still hold, although with some\\nminor differences.',\n",
              " 'Error description\\nThe faulty mutation operator in the original paper would, for each\\ngene in the genome, check if it would mutate (vs. the mutation\\nprobability), but then, instead of adding an amount of Gaussian\\nnoise to mutate the variable, would set it to 1.0. This was caused\\nby the code that was supposed to limit the variable to a range\\nbetween 0.0 and 1.0. The variable limits were switched during the\\nfunction call, so the code applied a lower limit of 1.0 to all values\\nafter mutation. While this still implements “a” form of mutation,\\nthese were not the dynamics intended by us, nor the ones described\\nin the paper. The plots in the original paper were produced with\\nthe mutation operator working like this in all instances mentioned. In the following section, we will provide updated plots with the\\nmutation operator working as described in the original paper. Norm emergence (Results Hold)\\nIn our amended simulation norms still emerge according to our\\ndefinition: They converge on a particular value through a reduction\\nin variance (Fig. 8) are to a certain extent arbitrary (Fig. 7)\\n(path dependent), i.e. they are not determined by environmental\\nscaffolding. Therefore our definition is intact. When\\ncomparing\\ndeterministic\\nand\\nprobabilistic\\nnorm\\nemergence we also see largely similar dynamics to the original\\nsimulation; reduction in variance in the bite size norm (Fig. 8)\\nin both cases but the average is more chaotic in the probabilistic\\ncase i.e. unstable norm emergence (Fig. 7). In addition, we also\\nran the simulations for longer as well and showed that bite size (in\\nboth deterministic and probabilistic conditions) seems to slowly\\ncreep upwards over time. This change is probably due to the fact\\nof the evolutionary incentive to consume more resource in order to\\nreproduce.',\n",
              " 'Ordinarily, this would trigger sanctions and prevent an\\nincrease in bite size in the population; however, these changes are\\nsmaller than the variance in the population, therefore not triggering\\nsignificant sanctions to counteract them. This effect is due to the\\ncontinuous nature of the simulation. N.B. Smaller populations still have an issue that there is less\\nvariance so may be harder to make that point for norm convergence\\nin the probabilistic case. Probabilistic vs Deterministic Population Level\\nProperties\\n1. Probabilistic populations are smaller, this result carries over to\\nthe new simulation (result holds). A difference here is that that\\nthe population average is larger for both conditions in the new\\nsimulation, however this is due to the simulation being run for\\nmore time steps in the new simulations so the simulations grow\\nmore than in the old simulation. 2. Probabilistic populations are more hypocritical, this result\\ncarries over to the new simulation (result holds/is stronger). 3. Probabilistic populations have less variance but this may be\\ndue to smaller populations in the probabilistic case (conclusion\\nunclear). This is in contrast to the original paper result where\\nprobabilistic populations had more variance despite a smaller\\npopulation. 4. Probabilistic agents seem to punish each other more. In fact this\\ndifference not only remains in the new data but is even larger in\\nthe new data (results hold/is stronger). 5. Bite sizes are largely the same across both populations (result\\nno longer holds). This contrasts with the original result of the\\nprobabilistic population being more selfish (higher average bite-\\nsize). This being said, despite having a much smaller population\\ncompared the the deterministic population (and therefore less\\npotential competition) the probabilistic bite size size is similar. So bite sizes may be similar but only due to the difference in\\npopulation size. (Fig.',\n",
              " '8 b, top row). Evolution of Noise (Results Hold)\\nRegarding the evolutionary dynamics of noise, the main claim\\nholds:\\nnoise does not seem to evolve away despite being\\ndetrimental to the population. However, noise does not increase\\nin some cases as in the original results (see sanction threshold\\nnoise in Fig 9a). In the case of the new mutation operator, it\\nseems as if noise just does not evolve, suggesting that despite noise\\nbeing detrimental, there may be no local gradient for it to evolve\\naway. We also analysed the “successful” runs (where we show\\nonly the runs that have populations > 1000). We see that when\\nwe select runs at the group level for their population size, sanction\\nnoise remains at the same level. However, bite-size noise seems\\nto decrease over time, suggesting that for runs that we artificially\\nselect for at the group level, there is a decrease in noise. However,\\nit should be noted that these are the subset of runs that decreased in\\nnoise via evolutionary drift, which we then selected for and plotted\\nafter the simulation. These changes do not occur due to individual-\\nlevel selection alone (Fig. 9b). Overall, these results suggest that\\nalthough lower noise is better for group success (population size)\\noverall, individual-level selection is not enough for noise to evolve\\naway; this is the same conclusion as with the original simulation. (a) This is the old data with the malfunctioning mutation operator,\\nN = 34 per condition. Each simulation is 5000 time steps. (b) This is the new data with the functioning mutation operator,\\nN = 100 per condition. Each simulation is 10000 time steps. Figure 7: The average value of each trait in the population plotted over time. Deterministic (left) and probabilistic (right).',\n",
              " 'Individual runs are plotted as coloured lines and the average of those runs is plotted as a black line. The main trends carry\\nover from the old simulation to the new one: both show that the deterministic simulations seem to settle on a norm whereas\\nthe probabilistic simulations are a lot more chaotic. There are some differences 1: that average bite size is similar between\\nconditions in the new simulation but not on the old. 2: the sanction threshold and sanction strength averages tend toward the\\nmiddle instead of toward the top of the range. (a) This is the old data with the malfunctioning mutation\\noperator,each simulation was run for 500 time steps. (b) This is the new data with the functioning mutation operator, each\\nsimulation was run for 10000 time steps. Figure 8: Various agent and population properties plotted over time. Deterministic (left) and probabilistic (right). Individual\\nruns are plotted as coloured lines and the average of those runs is plotted as a black line. N = 100 per condition. Although most\\ntrends are preserved, there are a few differences: 1. the bite size average in the original population is different when comparing\\nprobabilistic and deterministic conditions, with the average bite size tending to be more selfish. In the new simulation there is\\nno such difference. 2. The population differences remain (deterministic being larger) although the average is smaller in the new\\nsimulation. 3. There are more hypocrites in the probabilistic conditions in the new simulation, confirming the old simulation. 4. The amount of variance is larger for probabilistic in the old simulation, but this is not the case in the new simulation, with\\nthe variance being the same for both probabilistic and deterministic.',\n",
              " 'Finally, under the \"injuries due to sanctions\" plot (shows\\nenergy agents lose due to punishment) the new simulation confirms the old simulation results; with probabilistic populations\\nlosing more energy due to higher levels of punishment. (a) This is the old data with the malfunctioning mutation operator. N\\n= 34 per condition. Simulation was 5000 steps\\n(b) This is the new data with the functioning mutation operator. N =\\n100 per condition. Simulation was 10000 steps\\nFigure 9: The average standard deviation (noise) for each trait plotted over time. All runs (left) and only runs with\\npopulations > 1000 (right). Individual runs are plotted as coloured lines and the average of those runs is plotted as a black\\nline. In the old simulation we see that there is generally a small increase in noise when all runs are considered and noise stays\\nthe same when only successful runs are considered (with the exception of sanction strength noise which increases). This is a\\nstrange overall result in where despite the negative effects of noise, it doesn’t evolve away. In the new simulation, the main trend\\nis preserved in that noise doesn’t evolve away for any of the traits, however it stays the same instead of increasing. Further, it\\nseems that if we look at only successful runs (This is when select runs at the group level for their population) bite size noise\\nseems to decrease, further confirming that noise is detrimental at the group level and yet isn’t selected for at the individual level. Overall, a lower level of bite size noise is beneficial to the group, strangely, it is not selected against by evolution.']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Convert Chunks into Embeddings using Sentence Transformers"
      ],
      "metadata": {
        "id": "qL09ipz-XG7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # or any other HuggingFace model\n",
        "\n",
        "def get_embeddings(chunks):\n",
        "    return model.encode(chunks)"
      ],
      "metadata": {
        "id": "3rHU9T-5XHSx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=  get_embeddings(chunks)\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN6HivADXLmX",
        "outputId": "bf7a48c8-f9f4-447e-e691-a736dd068fee"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03070017, -0.06606123, -0.09377114, ...,  0.02346476,\n",
              "        -0.02628483, -0.07389904],\n",
              "       [-0.07668386, -0.02485039, -0.10057943, ..., -0.03395756,\n",
              "        -0.07292785, -0.0096894 ],\n",
              "       [-0.02396323, -0.11088822, -0.083583  , ...,  0.0373457 ,\n",
              "        -0.04568674, -0.01966629],\n",
              "       ...,\n",
              "       [-0.06986897, -0.0629409 ,  0.05596201, ...,  0.01489595,\n",
              "        -0.04363016, -0.01387018],\n",
              "       [-0.0821212 , -0.0379324 , -0.02623501, ..., -0.07212733,\n",
              "        -0.03868184, -0.02542508],\n",
              "       [-0.04388836, -0.024596  ,  0.01417989, ..., -0.08192163,\n",
              "        -0.02370076, -0.0494038 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Store Embeddings in FAISS Vector Store"
      ],
      "metadata": {
        "id": "p5zmj-nHXfUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu -q\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n"
      ],
      "metadata": {
        "id": "WEuwrPiGXijh"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_index = create_faiss_index(embeddings)\n",
        "faiss_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ovnThSmX-FD",
        "outputId": "7d19afc7-1cd9-4af6-c88b-bdcc0fcac825"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7f517bb4acd0> >"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_mapping(chunks, path=\"chunk_mapping.pkl\"):\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(chunks, f)\n",
        "    return chunks\n",
        "\n",
        "chunk_mapping = save_mapping(chunks)\n",
        "if chunk_mapping is None:\n",
        "    print(\"chunk_mapping is None! Fix text chunk creation or loading.\")\n",
        "else:\n",
        "    print(\"chunk_mapping saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYfOIpIAZMEA",
        "outputId": "b1e924e6-b3d3-416a-833f-0c86f5618329"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk_mapping saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: RAG pipeline"
      ],
      "metadata": {
        "id": "DZcJfd5HmHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_chunks(query, model, index, chunk_mapping, top_k=3):\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
        "    return [chunk_mapping[i] for i in indices[0]]\n",
        "# result = retrieve_similar_chunks('What are the main benefits of using AI according to the document?', model, faiss_index, chunk_mapping)\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "4alECxmeYs4M"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def generate_answer_from_llm(context, query, api_key):\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use the context below to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",  # ✅ from your curl\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.2,\n",
        "            \"max_tokens\": 1024\n",
        "        }\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"API error {response.status_code}: {response.text}\")\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    if 'choices' not in data:\n",
        "        raise Exception(f\"'choices' not found in response: {data}\")\n",
        "\n",
        "    return data['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "context = \"\\n\".join(result)\n",
        "# result_1 = generate_answer_from_llm(context, 'What are the main benefits of using AI according to the document?', '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')\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "01MK7RtfYu41"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_pipeline(query, faiss_index, model, chunk_mapping, api_key):\n",
        "    retrieved_chunks = retrieve_similar_chunks(query, model, faiss_index, chunk_mapping)\n",
        "    context = \"\\n\".join(retrieved_chunks)\n",
        "    answer = generate_answer_from_llm(context, query, api_key)\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "unlUSCr6Y1xd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Getting Response"
      ],
      "metadata": {
        "id": "7zpqUVLJaFHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What are the main benefits of using AI according to the document?'\n",
        "api_key = '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'\n",
        "result = rag_pipeline(query, faiss_index, model, chunk_mapping, api_key)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "ui7hSDoMZc-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11381f3a-976a-4f78-9db4-624aaccddce6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document does not mention the main benefits of using AI. The text appears to be a research paper discussing the emergence of social norms in agent-based models, the effects of noise on these norms, and the evolutionary dynamics of noise. It does not mention Artificial Intelligence (AI) or its benefits.\n"
          ]
        }
      ]
    }
  ]
}